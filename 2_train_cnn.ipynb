{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diseño de la entrada de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\achav\\Documents\\Osteoartritis\\venv\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "imagen_alto = 128\n",
    "imagen_ancho = 128\n",
    "canales_de_color = 3\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\", input_shape=(imagen_alto, imagen_ancho, canales_de_color)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "input_shape = tf.keras.Input(shape=(imagen_alto, imagen_ancho, canales_de_color))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,211,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m3,211,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,267,908</span> (12.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,267,908\u001b[0m (12.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,267,908</span> (12.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,267,908\u001b[0m (12.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir la arquitectura de la CNN\n",
    "model = models.Sequential([\n",
    "    (input_shape),  # Capa de entrada (128x128x1)\n",
    "    data_augmentation,\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(4, activation='softmax')  # Capa de salida (2 neuronas, una por cada clase)\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: 'assets\\\\296-19_001\\\\resized\\\\class_D'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m plate \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(data_dir):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m clase \u001b[38;5;129;01min\u001b[39;00m clases:\n\u001b[1;32m---> 19\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(data_dir \u001b[38;5;241m/\u001b[39m plate \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresized\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m clase):\n\u001b[0;32m     20\u001b[0m             \u001b[38;5;66;03m# Leer la imagen\u001b[39;00m\n\u001b[0;32m     21\u001b[0m             imagen \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;28mstr\u001b[39m(data_dir \u001b[38;5;241m/\u001b[39m plate \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresized\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m clase \u001b[38;5;241m/\u001b[39m file), cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR)\n\u001b[0;32m     23\u001b[0m             \u001b[38;5;66;03m# Normalizar la imagen\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] El sistema no puede encontrar la ruta especificada: 'assets\\\\296-19_001\\\\resized\\\\class_D'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dir = pathlib.Path('assets')\n",
    "\n",
    "# Lista para almacenar las imágenes y etiquetas\n",
    "imagenes = []\n",
    "etiquetas = []\n",
    "\n",
    "# Clases disponibles\n",
    "clases = ['class_A', 'class_B', 'class_C',]\n",
    "\n",
    "# Recorrer las carpetas de las clases\n",
    "for plate in os.listdir(data_dir):\n",
    "    for clase in clases:\n",
    "        for file in os.listdir(data_dir / plate / 'resized' / clase):\n",
    "            # Leer la imagen\n",
    "            imagen = cv2.imread(str(data_dir / plate / 'resized' / clase / file), cv2.IMREAD_COLOR)\n",
    "            \n",
    "            # Normalizar la imagen\n",
    "            imagen = imagen / 255.0\n",
    "            # Agregar la imagen a la lista\n",
    "            imagenes.append(imagen)\n",
    "            # Agregar la etiqueta a la lista en el formato [1, 0] o [0, 1]\n",
    "            etiquetas.append([0, 1, 0] if clase == 'class_B' else [1, 0, 0])\n",
    "\n",
    "# Convertir las listas de imágenes y etiquetas a arrays numpy\n",
    "imagenes = np.array(imagenes)\n",
    "etiquetas = np.array(etiquetas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alistamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir los datos en entrenamiento y validación\n",
    "imagenes_entrenamiento, imagenes_validacion, etiquetas_entrenamiento, etiquetas_validacion = train_test_split(imagenes, etiquetas, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convertir las listas de imágenes y etiquetas de entrenamiento a arrays numpy\n",
    "imagenes_entrenamiento = np.array(imagenes_entrenamiento)\n",
    "etiquetas_entrenamiento = np.array(etiquetas_entrenamiento)\n",
    "\n",
    "# Convertir las listas de imágenes y etiquetas de validación a arrays numpy\n",
    "imagenes_validacion = np.array(imagenes_validacion)\n",
    "etiquetas_validacion = np.array(etiquetas_validacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "num_epochs = 12\n",
    "batch_size = 32\n",
    "\n",
    "# Directorio donde se guardarán los registros para TensorBoard\n",
    "# directorio_logs = \"logs/\"\n",
    "\n",
    "# Callback de TensorBoard\n",
    "# tensorboard_callback = TensorBoard(log_dir=directorio_logs, histogram_freq=1)\n",
    "\n",
    "# Entrenar el modelo con el callback de TensorBoard\n",
    "model.fit(\n",
    "    imagenes_entrenamiento, etiquetas_entrenamiento,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(imagenes_validacion, etiquetas_validacion)\n",
    "print('Precisión en datos de prueba:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardado del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('pesos_modelo_cnn.weights.h5')\n",
    "model.save(filepath='modelo_cnn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a sound when done\n",
    "\n",
    "import winsound\n",
    "frequency = 880  # Set Frequency To 2500 Hertz\n",
    "\n",
    "duration = 700  # Set Duration To 1000 ms == 1 second\n",
    "\n",
    "winsound.Beep(frequency, duration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar el modelo y los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = models.load_model('modelo_cnn.keras')\n",
    "\n",
    "# loaded_model.load_weights('pesos_modelo_cnn.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar una imagen de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OPENSLIDE_PATH = r'C:\\Users\\achav\\Documents\\Osteoartritis\\openslide-win64\\bin'\n",
    "\n",
    "if hasattr(os, 'add_dll_directory'):\n",
    "    # Windows\n",
    "    with os.add_dll_directory(OPENSLIDE_PATH):\n",
    "        import openslide\n",
    "        print('Using OpenSlide from', openslide.__file__)\n",
    "else:\n",
    "    import openslide\n",
    "\n",
    "plate_name = \"Ms-13-22-1_001\"\n",
    "plate_path = plate_name + \".svs\"\n",
    "path = f\"assets/{plate_path}\"\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.isfile(path):\n",
    "    print(f\"File {path} not found\")\n",
    "\n",
    "slide = openslide.OpenSlide(path)\n",
    "\n",
    "# Get a thumbnail of the whole slide\n",
    "thumbnail = slide.get_thumbnail((slide.dimensions[0] // 64, slide.dimensions[1] // 64))\n",
    "\n",
    "# Convert the thumbnail to a numpy array\n",
    "thumbnail = np.array(thumbnail)\n",
    "\n",
    "# Display the thumbnail\n",
    "plt.imshow(thumbnail)\n",
    "\n",
    "plate_name = \"Ms-13-22-1_001\"\n",
    "plate_path = plate_name + \".svs\"\n",
    "path = f\"assets/{plate_path}\"\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.isfile(path):\n",
    "    print(f\"File {path} not found\")\n",
    "\n",
    "slide = openslide.OpenSlide(path)\n",
    "\n",
    "# Get a thumbnail of the whole slide\n",
    "thumbnail = slide.get_thumbnail((slide.dimensions[0] // 64, slide.dimensions[1] // 64))\n",
    "\n",
    "# Convert the thumbnail to a numpy array\n",
    "thumbnail = np.array(thumbnail)\n",
    "\n",
    "# Display the thumbnail\n",
    "plt.imshow(thumbnail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "class_colors = {0: (255, 0, 0), 1: (0, 255, 0), 2: (0, 0, 255)}\n",
    "level = 0\n",
    "\n",
    "# Get the dimensions of the slide\n",
    "width, height = slide.level_dimensions[level]\n",
    "\n",
    "print(slide.level_dimensions)\n",
    "print(slide.level_downsamples)\n",
    "print(width, height)\n",
    "\n",
    "# Create a count dict to store the number of tiles for each class\n",
    "count = defaultdict(int)\n",
    "\n",
    "original = np.array(slide.read_region((0, 0), level, (width, height)).convert(\"RGB\"))\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "# results = np.zeros((width, height, 3), dtype=np.uint8)\n",
    "\n",
    "# print(results.shape)\n",
    "for i in range(0, 1023, 1024):\n",
    "    print(f\"i: {i} / {height}\")\n",
    "    for j in range(0, 1023, 1024):\n",
    "        print(f\"j: {j} / {width}\")\n",
    "        try:\n",
    "            \n",
    "            image = slide.read_region((i, j), level, (256, 256)).convert(\"RGB\")\n",
    "            # Show thumbnail\n",
    "            image = image.resize((128, 128))  # Ajustar al tamaño esperado por el modelo\n",
    "            image = np.array(image)\n",
    "            # plt.imshow(image)\n",
    "\n",
    "            # Asegurarse de que la imagen tiene la forma correcta (128, 128, 3)\n",
    "            image = np.expand_dims(image, axis=0)  # Añadir una dimensión para el batch\n",
    "            # Hacer predicción con el modelo\n",
    "            prediction = model.predict(image, verbose=0)\n",
    "            print(prediction)\n",
    "            # Obtener la clase con la mayor probabilidad\n",
    "            prediction = np.argmax(prediction)\n",
    "            # print(f\"Prediction: {prediction}\")\n",
    "            \n",
    "            # Pintar la región de la imagen original con el color de la clase predicha\n",
    "            # cv2.rectangle(original, (i, j), (i + 256, j + 256), class_colors[prediction], 100)\n",
    "            # cv2.rectangle(results, (i, j), (i + 256, j + 256), class_colors[prediction], -1)\n",
    "            \n",
    "            # Ajustar el tamaño del bloque a 4x4 en la matriz de resultados\n",
    "            count[prediction] += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            winsound.Beep(880, 1000)\n",
    "            print(e)\n",
    "\n",
    "\n",
    "        # Compare original image with the predicted image\n",
    "        #plt.figure(figsize=(10, 10))\n",
    "        #plt.subplot(1, 2, 1)\n",
    "        #thumbnail = cv2.resize(original, (width // 64, height// 64))\n",
    "        #plt.imshow(thumbnail)\n",
    "        #plt.title(\"Original Image\")\n",
    "        #plt.axis(\"off\")\n",
    "\n",
    "        #plt.subplot(1, 2, 2)\n",
    "\n",
    "        ## Resize the results to the same size as the original image\n",
    "        #resultados = cv2.resize(results, (thumbnail.shape[1], thumbnail.shape[0]))\n",
    "\n",
    "        #plt.imshow(resultados)\n",
    "        #plt.title(\"Predicted Image\")\n",
    "        #plt.axis(\"off\")\n",
    "\n",
    "        #plt.show()\n",
    "        \n",
    "\n",
    "# Reduce in a factor of 4\n",
    "# cv2.imwrite(\"original.png\", cv2.resize(thumbnail, (width, height), interpolation=cv2.INTER_NEAREST))\n",
    "# cv2.imwrite(\"results.png\", cv2.resize(results, (width, height), interpolation=cv2.INTER_NEAREST))\n",
    "\n",
    "winsound.Beep(880, 1000)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original image with the predicted image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(thumbnail)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "# Resize the results to the same size as the original image\n",
    "results = cv2.resize(results, (thumbnail.shape[1], thumbnail.shape[0]))\n",
    "\n",
    "plt.imshow(results)\n",
    "plt.title(\"Predicted Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
