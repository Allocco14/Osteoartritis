{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,050</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m2,050\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,888,392</span> (114.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,888,392\u001b[0m (114.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,100,226</span> (8.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,100,226\u001b[0m (8.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,200,454</span> (16.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m4,200,454\u001b[0m (16.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path_model = 'modelo_cnn_20240923025056.keras'\n",
    "\n",
    "# Cargar los pesos en el modelo\n",
    "model = models.load_model(path_model)\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular una matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros\n",
    "data_dir = 'data'\n",
    "batch_size = 32\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "# Generador de validación\n",
    "val_dataset = image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,   # 20% validación\n",
    "    subset=\"validation\",    # Usar el conjunto de validación\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'\n",
    ").map(lambda x, y: (x / 255.0, y))  # Normalizar las imágenes\n",
    "\n",
    "# Obtener las etiquetas verdaderas y las imágenes\n",
    "true_labels = []\n",
    "predictions = []\n",
    "\n",
    "for images, labels in val_dataset:\n",
    "    # Obtener las predicciones del modelo\n",
    "    preds = model.predict(images, verbose=0)\n",
    "    predictions.extend(np.argmax(preds, axis=1))  # Convertir las predicciones a clases\n",
    "    true_labels.extend(np.argmax(labels.numpy(), axis=1))  # Convertir las etiquetas a clases\n",
    "\n",
    "# Convertir a arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Crear un DataFrame de pandas con la matriz de confusión\n",
    "clases = ['Sinovio', 'Estroma', ]\n",
    "df_cm = pd.DataFrame(cm, index=clases, columns=clases)\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df_cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.xlabel('Clase predicha')\n",
    "plt.ylabel('Clase real')\n",
    "plt.title('Matriz de confusión')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar openslide "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OpenSlide from c:\\Users\\achav\\Documents\\Osteoartritis\\venv\\Lib\\site-packages\\openslide\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "OPENSLIDE_PATH = r'C:\\Users\\achav\\Documents\\Osteoartritis\\openslide-win64\\bin'\n",
    "\n",
    "if hasattr(os, 'add_dll_directory'):\n",
    "    # Windows\n",
    "    with os.add_dll_directory(OPENSLIDE_PATH):\n",
    "        import openslide\n",
    "        print('Using OpenSlide from', openslide.__file__)\n",
    "else:\n",
    "    import openslide\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m thumbnail \u001b[38;5;241m=\u001b[39m slide\u001b[38;5;241m.\u001b[39mget_thumbnail((slide\u001b[38;5;241m.\u001b[39mdimensions[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m256\u001b[39m, slide\u001b[38;5;241m.\u001b[39mdimensions[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m256\u001b[39m))\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Convert the thumbnail to a numpy array\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m thumbnail \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray(thumbnail)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Display the thumbnail\u001b[39;00m\n\u001b[0;32m     23\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(thumbnail)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "plate_name = \"602-1-19_001\"\n",
    "filename = plate_name + \".svs\"\n",
    "dir_path = f\"D:/\"\n",
    "file_path = f\"{dir_path}/{filename}\"\n",
    "\n",
    "absolute_path = os.path.abspath(file_path)\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.isfile(file_path):\n",
    "    print(f\"File {file_path} not found\")\n",
    "\n",
    "slide = openslide.OpenSlide(file_path)\n",
    "\n",
    "# Get a thumbnail of the whole slide\n",
    "thumbnail = slide.get_thumbnail((slide.dimensions[0] // 256, slide.dimensions[1] // 256))\n",
    "\n",
    "# Convert the thumbnail to a numpy array\n",
    "thumbnail = np.array(thumbnail)\n",
    "\n",
    "# Display the thumbnail\n",
    "plt.imshow(thumbnail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predecir y crear una nueva imagen con las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from collections import defaultdict\n",
    "\n",
    "class_colors = {0: (255, 0, 0), 1: (0, 0, 255), 2: (0, 255, 0)}\n",
    "level = 0\n",
    "\n",
    "# Get the dimensions of the slide\n",
    "width, height = slide.level_dimensions[level]\n",
    "\n",
    "print(slide.level_dimensions)\n",
    "print(slide.level_downsamples)\n",
    "print(width, height)\n",
    "\n",
    "downsized_image = slide.get_thumbnail((slide.level_dimensions[level][0] // 512, slide.level_dimensions[level][1] // 512))\n",
    "downsized_image = np.array(downsized_image)\n",
    "results = np.zeros((slide.level_dimensions[level][1] // 512, slide.level_dimensions[level][0] // 512, 3), dtype=np.uint8)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "print(downsized_image.shape, results.shape)\n",
    "\n",
    "# Create a count dict to store the number of tiles for each class\n",
    "count = defaultdict(int)\n",
    "\n",
    "# print(results.shape)\n",
    "\n",
    "total = width * height // (512 * 512)\n",
    "\n",
    "for i in range(0, width, 512):    \n",
    "    for j in range(0, height, 512):\n",
    "        try:\n",
    "            image = slide.read_region((i, j), level, (512, 512)).convert(\"RGB\")\n",
    "            # Show thumbnail\n",
    "            image = image.resize((128, 128))\n",
    "\n",
    "            image = np.array(image)\n",
    "\n",
    "            # Calcular el promedio de los píxeles\n",
    "            white_pixels = np.mean(image)\n",
    "\n",
    "            # print(f\"White pixels: {white_pixels.round(0)}\")\n",
    "\n",
    "            # Si la región es muy blanca, no hacer predicción\n",
    "            if white_pixels > 230:\n",
    "                # cv2.rectangle(results, (i // 512, j // 512), (i // 512 + 1, j // 512 + 1), (255, 255, 255), -1)\n",
    "                continue\n",
    "\n",
    "            # Normalizar la imagen\n",
    "            image = image / 255.0\n",
    "            \n",
    "            # Añadir una dimensión para el batch\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "\n",
    "            # Hacer predicción con el modelo\n",
    "            prediction = model.predict(image, verbose=0)\n",
    "\n",
    "            # Obtener la clase con la mayor probabilidad\n",
    "            prediction = np.argmax(prediction)\n",
    "            predictions.append((i, j, prediction))\n",
    "\n",
    "            count[prediction] += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            import winsound\n",
    "            winsound.PlaySound(\"SystemExclamation\", winsound.SND_ALIAS)\n",
    "            print(f\"Error: {e}\")\n",
    "    print(f\"Processed {i >> 9} of {width >> 9} rows. Percentage: {i * 100 // width} %\", end=\"\\r\")\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsize_scale = 16\n",
    "\n",
    "class_colors = {0: (255, 0, 0), 1: (0, 255, 0), 2: (0, 0, 255)}\n",
    "\n",
    "downsized_image = slide.get_thumbnail((slide.level_dimensions[level][0] // downsize_scale, slide.level_dimensions[level][1] // downsize_scale))\n",
    "downsized_image = np.array(downsized_image)\n",
    "results = np.ones((slide.level_dimensions[level][1] // downsize_scale, slide.level_dimensions[level][0] // downsize_scale, 3), dtype=np.uint8)*255\n",
    "\n",
    "# Convertir a imagen RGB\n",
    "downsized_image = cv2.cvtColor(downsized_image, cv2.COLOR_RGBA2RGB)\n",
    "results = cv2.cvtColor(results, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "print(downsized_image.shape, results.shape)\n",
    "\n",
    "for i, j, prediction in predictions:\n",
    "    # cv2.rectangle(downsized_image, (i // 512, j // 512), (i // 512 + 1, j // 512 + 1), class_colors[prediction], -1)\n",
    "    cv2.rectangle(results, (i // downsize_scale, j // downsize_scale), (i // downsize_scale + 256 // downsize_scale, j // downsize_scale + 256 // downsize_scale), class_colors[prediction], 3)\n",
    "\n",
    "\n",
    "cv2.imwrite(f\"results/png/{plate_name}_predictions.png\", cv2.cvtColor(downsized_image, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite(f\"results/png/{plate_name}_results.png\", cv2.cvtColor(results, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "## Tiff\n",
    "import tifffile as tiff\n",
    "\n",
    "tiff.imwrite(f\"results/tiff/{plate_name}_predictions.tiff\", downsized_image)\n",
    "tiff.imwrite(f\"results/tiff/{plate_name}_results.tiff\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "\n",
    "# Compare original image with the predicted image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(downsized_image)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "plt.imshow(results)\n",
    "plt.title(\"Predicted Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Play a sound of success when the process is finished\n",
    "winsound.PlaySound(\"SystemAsterisk\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el porcentaje por clase\n",
    "total = sum(count.values())\n",
    "for key in count:\n",
    "    count[key] = count[key] / total * 100\n",
    "\n",
    "print(count)\n",
    "\n",
    "with open(f\"results/{plate_name}_results.txt\", \"w\") as f:\n",
    "    f.write(str(count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
